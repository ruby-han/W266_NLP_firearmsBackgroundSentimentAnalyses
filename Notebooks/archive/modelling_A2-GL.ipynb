{"cells":[{"cell_type":"markdown","metadata":{"id":"nR8dyx0AHsVb"},"source":["### Import Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26594,"status":"ok","timestamp":1657596141698,"user":{"displayName":"Ruby Han","userId":"04168984288503987333"},"user_tz":300},"id":"W5paQvvxX1BS","outputId":"e087018f-62ba-4c94-f754-93242e0174b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 24.2 MB 1.2 MB/s \n","\u001b[K     |████████████████████████████████| 4.9 MB 8.5 MB/s \n","\u001b[K     |████████████████████████████████| 4.4 MB 7.9 MB/s \n","\u001b[K     |████████████████████████████████| 6.6 MB 43.5 MB/s \n","\u001b[K     |████████████████████████████████| 101 kB 11.9 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 67.6 MB/s \n","\u001b[?25h"]}],"source":["#@title Imports\n","\n","!pip install pydot --quiet\n","!pip install gensim==3.8.3 --quiet\n","!pip install tensorflow-datasets --quiet\n","!pip install -U tensorflow-text==2.8.2 --quiet\n","!pip install transformers --quiet\n","!pip install pydot --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yVCGGpRCDmWU"},"outputs":[],"source":["# Import packages\n","import pandas as pd\n","import numpy as np\n","from tensorflow import keras\n","\n","from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n","from tensorflow.keras.models import Model\n","import tensorflow.keras.backend as K\n","import tensorflow_datasets as tfds\n","import tensorflow_text as tf_text\n","\n","from google.colab import drive\n","\n","from collections import Counter\n","import matplotlib.pyplot as plt\n","from nltk.util import ngrams\n","\n","from transformers import BertTokenizer, TFBertModel\n","from tqdm.notebook import tqdm\n","from keras.preprocessing.sequence import pad_sequences\n","\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","\n","\n","import time\n","from transformers import create_optimizer\n","\n","import sklearn as sk\n","import os\n","import nltk\n","from nltk.corpus import reuters\n","from nltk.data import find\n","\n","import re\n","\n","import gensim"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23192,"status":"ok","timestamp":1657596175256,"user":{"displayName":"Ruby Han","userId":"04168984288503987333"},"user_tz":300},"id":"NFPBnrozD6RK","outputId":"7fa58d9a-41d0-4e97-d037-61b6afe89bae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /drive\n","/drive/.shortcut-targets-by-id/1p1bDkEjmNKPzX456WZWBr8qtvPr6Pt5m/W266 Project/Colab Notebooks/Exploration\n","/drive/.shortcut-targets-by-id/1p1bDkEjmNKPzX456WZWBr8qtvPr6Pt5m/W266 Project/Colab Notebooks/Exploration\n"]}],"source":["drive.mount('/drive') \n","%cd /drive/MyDrive/W266 Project/Colab Notebooks/Exploration\n","!pwd"]},{"cell_type":"markdown","metadata":{"id":"xPWjxRSHoA6p"},"source":["# Model - BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eWpis5aUnysI"},"outputs":[],"source":["final_train = pd.read_csv('../../data/transformed/final/train.csv')\n","final_test = pd.read_csv('../../data/transformed/final/test.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"elapsed":2609,"status":"ok","timestamp":1657590082328,"user":{"displayName":"Gerrit Lensink","userId":"03001139976263396963"},"user_tz":420},"id":"p7GY1WTXojZW","outputId":"584ba3d8-08be-4bc4-8932-e46dec4110b5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                 comment_text_transf  violent\n","0       cocksucker before you piss around on my work        1\n","1  hey  what is it.. @ | talk . what is it  an ex...        1\n","2  bye   don't look, come or think of comming bac...        1\n","3  you are gay or antisemmitian.   archangel whit...        1\n","4            fuck your filthy mother in the ass, dry        1"],"text/html":["\n","  <div id=\"df-1d4de66d-077e-4ced-9ea8-70049fe037a3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment_text_transf</th>\n","      <th>violent</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cocksucker before you piss around on my work</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>hey  what is it.. @ | talk . what is it  an ex...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>bye   don't look, come or think of comming bac...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>you are gay or antisemmitian.   archangel whit...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>fuck your filthy mother in the ass, dry</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d4de66d-077e-4ced-9ea8-70049fe037a3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1d4de66d-077e-4ced-9ea8-70049fe037a3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1d4de66d-077e-4ced-9ea8-70049fe037a3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}],"source":["final_train.head()"]},{"cell_type":"markdown","source":["Import helper functions"],"metadata":{"id":"zuyES9gnEXHw"}},{"cell_type":"code","source":["#@title Plotting Function\n","\n","# 4-window plot. Small modification from matplotlib examples.\n","\n","def make_plot(axs, history1, \n","              history2, \n","              y_lim_loss_lower=0.4, \n","              y_lim_loss_upper=0.6,\n","              y_lim_accuracy_lower=0.7, \n","              y_lim_accuracy_upper=0.8,\n","              model_1_name='model 1',\n","              model_2_name='model 2',\n","              \n","             ):\n","    box = dict(facecolor='yellow', pad=5, alpha=0.2)\n","\n","    ax1 = axs[0, 0]\n","    ax1.plot(history1.history['loss'])\n","    ax1.plot(history1.history['val_loss'])\n","    ax1.set_title('loss - ' + model_1_name)\n","    ax1.set_ylabel('loss', bbox=box)\n","    ax1.set_ylim(y_lim_loss_lower, y_lim_loss_upper)\n","\n","    ax3 = axs[1, 0]\n","    ax3.set_title('accuracy - ' + model_1_name)\n","    ax3.plot(history1.history['accuracy'])\n","    ax3.plot(history1.history['val_accuracy'])\n","    ax3.set_ylabel('accuracy', bbox=box)\n","    ax3.set_ylim(y_lim_accuracy_lower, y_lim_accuracy_upper)\n","\n","\n","    ax2 = axs[0, 1]\n","    ax2.set_title('loss - ' + model_2_name)\n","    ax2.plot(history2.history['loss'])\n","    ax2.plot(history2.history['val_loss'])\n","    ax2.set_ylim(y_lim_loss_lower, y_lim_loss_upper)\n","\n","    ax4 = axs[1, 1]\n","    ax4.set_title('accuracy - ' + model_2_name)\n","\n","    # small adjustment to account for the 2 accuracy measures in the Weighted Averging Model with Attention\n","    if 'classification_accuracy' in history2.history.keys():\n","      ax4.plot(history2.history['classification_accuracy'])\n","    else:\n","      ax4.plot(history2.history['accuracy'])\n","    \n","    if 'val_classification_accuracy' in history2.history.keys():\n","      ax4.plot(history2.history['val_classification_accuracy'])\n","    else:\n","      ax4.plot(history2.history['val_accuracy'])\n","    ax4.set_ylim(y_lim_accuracy_lower, y_lim_accuracy_upper)"],"metadata":{"id":"5JG43fibEWq1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n","bert_model = TFBertModel.from_pretrained('bert-base-cased') # a quick test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":154,"referenced_widgets":["fb20b9af30724c0fbb59db0630dc4004","2975cd35c5e54fe8af2d38ca5c67270c","f78b5a9dff6641538b7f24c1e34b2452","566c114529044db3a4c50ab0b08df550","0a28eb09750b4c5da22353add8e1ecb2","bd29d7dfdae14dc881cdfc767956d89c","7345635474ce4aa88e7e37b48e27f98b","d43e93cedff64d3ab1cc0600ca0721e7","7d2d0f7c224d41148db406d58bb7fa0e","e0496b8d82ff442e8c1708aa440831c4","a0faf8e097c4497e8948d93b83937690"]},"id":"8MHhB1yeErJB","executionInfo":{"status":"ok","timestamp":1657593775067,"user_tz":420,"elapsed":15955,"user":{"displayName":"Gerrit Lensink","userId":"03001139976263396963"}},"outputId":"c7dd3e90-970e-46d4-c930-b99833b883d9"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/502M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb20b9af30724c0fbb59db0630dc4004"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]}]},{"cell_type":"code","source":["max_length = 128\n","\n","x_train = bert_tokenizer(list(final_train['comment_text_transf']),\n","                         max_length = max_length,\n","                         truncation = True,\n","                         padding = 'max_length',\n","                         return_tensors = 'tf')\n","y_train = list(final_train['violent'])"],"metadata":{"id":"6Nh-6diNErGJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_test = bert_tokenizer(list(final_test['comment_text_transf'].apply(str)),\n","                         max_length = max_length,\n","                         truncation = True,\n","                         padding = 'max_length',\n","                         return_tensors = 'tf')\n","y_test = list(final_test['violent'])"],"metadata":{"id":"V3skPllBErDj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_bert_cls_model(hidden_size = 100, dropout = .3, learning_rate = .00005):\n","    bert_model = TFBertModel.from_pretrained('bert-base-cased')\n","\n","    # Build the input layers\n","    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='input_ids_layer')\n","    # token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='token_type_ids_layer')\n","    # attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='attention_mask_layer')\n","\n","    # Dictionary of inputs\n","    # bert_inputs = {'input_ids': input_ids,\n","    #                'token_type_ids': token_type_ids,\n","    #                'attention_mask': attention_mask} \n","\n","    bert_inputs = {'input_ids': input_ids} \n","\n","    # model output\n","    bert_out = bert_model(bert_inputs) \n","\n","    # Instead of pooled token, using the 'cls' token \n","    # pooled_token = bert_out[1]\n","    cls_token = bert_out[0][:,0] # First layer, 0th column of each token set\n","\n","\n","    # Hidden layers\n","    hidden = tf.keras.layers.Dense(hidden_size, activation='relu', name='hidden_layer')(cls_token)\n","    hidden = tf.keras.layers.Dropout(dropout)(hidden)  \n","\n","    classification = tf.keras.layers.Dense(1, activation='sigmoid',name='classification_layer')(hidden)\n","\n","    # instantiate model\n","    # classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n","    classification_model = tf.keras.Model(inputs=input_ids, outputs=[classification])\n","    \n","    # compile model\n","    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","                            loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n","                            metrics='accuracy')\n","   \n","    ### END YOUR CODE\n","    \n","    return classification_model"],"metadata":{"id":"RzjsndOaTAYa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cls_model = create_bert_cls_model()\n","\n","\n","\n","cls_model_output = cls_model.fit(x_train, \n","                                np.array(y_train),   \n","                                validation_data=(x_test, np.array(y_test)),    \n","                                batch_size=8, \n","                                epochs=2) \n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":497},"id":"JP8un6p9TAVi","executionInfo":{"status":"error","timestamp":1657594935264,"user_tz":420,"elapsed":5334,"user":{"displayName":"Gerrit Lensink","userId":"03001139976263396963"}},"outputId":"b6f94993-acba-45bb-c61a-dd2fa7d9bc1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-85-c365bee5c532>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                                 epochs=2) \n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__make_cmp_key\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    424\u001b[0m       return (np.ndarray, value.shape,\n\u001b[1;32m    425\u001b[0m               TypeSpec.__nested_list_to_tuple(value.tolist()))\n\u001b[0;32m--> 426\u001b[0;31m     raise ValueError(f\"Cannot generate a hashable key for {self} because \"\n\u001b[0m\u001b[1;32m    427\u001b[0m                      \u001b[0;34mf\"the _serialize() method \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m                      f\"returned an unsupproted value of type {type(value)}\")\n","\u001b[0;31mValueError\u001b[0m: Cannot generate a hashable key for IteratorSpec(({'input_ids': TensorSpec(shape=(None, 128), dtype=tf.int32, name=None), 'token_type_ids': TensorSpec(shape=(None, 128), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(None, 128), dtype=tf.int32, name=None)}, TensorSpec(shape=(None,), dtype=tf.int64, name=None)),) because the _serialize() method returned an unsupproted value of type <class 'transformers.tokenization_utils_base.BatchEncoding'>"]}]},{"cell_type":"code","source":["print(len(x_train), len(y_train), len(x_test), len(y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"blcemlkmTAS-","executionInfo":{"status":"ok","timestamp":1657594889408,"user_tz":420,"elapsed":538,"user":{"displayName":"Gerrit Lensink","userId":"03001139976263396963"}},"outputId":"55d080d8-1a64-40a9-d12e-f32174bdef30"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3 159571 3 63978\n"]}]},{"cell_type":"code","source":["x_train[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"id":"M_Txl0KJWrSm","executionInfo":{"status":"error","timestamp":1657594918274,"user_tz":420,"elapsed":1198,"user":{"displayName":"Gerrit Lensink","userId":"03001139976263396963"}},"outputId":"2e76a725-e1a6-4efa-b7e6-ac97a604b5b8"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-84-267322372b12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             raise KeyError(\n\u001b[0;32m--> 241\u001b[0;31m                 \u001b[0;34m\"Indexing with integers (to access backend Encoding for a given batch index) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m                 \u001b[0;34m\"is not available when using Python based tokenizers\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             )\n","\u001b[0;31mKeyError\u001b[0m: 'Indexing with integers (to access backend Encoding for a given batch index) is not available when using Python based tokenizers'"]}]},{"cell_type":"code","source":["can you see this"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130},"id":"klppD24VWwXT","executionInfo":{"status":"error","timestamp":1657595192687,"user_tz":420,"elapsed":1115,"user":{"displayName":"Gerrit Lensink","userId":"03001139976263396963"}},"outputId":"b493d4ff-8ea9-48fe-d736-54695df2d2ca"},"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-86-a8796d18d88d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    can you see this\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"ujvDjQohX1tT"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"modelling_A2-GL.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"fb20b9af30724c0fbb59db0630dc4004":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2975cd35c5e54fe8af2d38ca5c67270c","IPY_MODEL_f78b5a9dff6641538b7f24c1e34b2452","IPY_MODEL_566c114529044db3a4c50ab0b08df550"],"layout":"IPY_MODEL_0a28eb09750b4c5da22353add8e1ecb2"}},"2975cd35c5e54fe8af2d38ca5c67270c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd29d7dfdae14dc881cdfc767956d89c","placeholder":"​","style":"IPY_MODEL_7345635474ce4aa88e7e37b48e27f98b","value":"Downloading: 100%"}},"f78b5a9dff6641538b7f24c1e34b2452":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d43e93cedff64d3ab1cc0600ca0721e7","max":526681800,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d2d0f7c224d41148db406d58bb7fa0e","value":526681800}},"566c114529044db3a4c50ab0b08df550":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0496b8d82ff442e8c1708aa440831c4","placeholder":"​","style":"IPY_MODEL_a0faf8e097c4497e8948d93b83937690","value":" 502M/502M [00:09&lt;00:00, 62.4MB/s]"}},"0a28eb09750b4c5da22353add8e1ecb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd29d7dfdae14dc881cdfc767956d89c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7345635474ce4aa88e7e37b48e27f98b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d43e93cedff64d3ab1cc0600ca0721e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d2d0f7c224d41148db406d58bb7fa0e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e0496b8d82ff442e8c1708aa440831c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0faf8e097c4497e8948d93b83937690":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}